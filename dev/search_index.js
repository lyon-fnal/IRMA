var documenterSearchIndex = {"docs":
[{"location":"mpi/#MPI-helper-functions","page":"MPI helper functions","title":"MPI helper functions","text":"","category":"section"},{"location":"mpi/","page":"MPI helper functions","title":"MPI helper functions","text":"This IRMA package contains some helper functions for MPI.","category":"page"},{"location":"mpi/","page":"MPI helper functions","title":"MPI helper functions","text":"mpiGatherSerialized will serialize an object and do an MPI Gather operation on it. For example,","category":"page"},{"location":"mpi/","page":"MPI helper functions","title":"MPI helper functions","text":"\nallHistos = mpiGatherSerialized(hists, isroot, root, comm)\nif isroot\n    # Do something with allHistos\nend","category":"page"},{"location":"shist/#Static-Histograms","page":"Static Histograms","title":"Static Histograms","text":"","category":"section"},{"location":"shist/","page":"Static Histograms","title":"Static Histograms","text":"OnlineStats.Hist histograms are used extensively in IRMA analysis code. Because Hist uses dynamic arrays, it is not a Julia isbitstype. This means that you must serialize/deserialize histograms if you want to pass them between MPI ranks. A SHist or Static Histogram uses a SVector from StaticArrays.jl, making an isbitstype. Therefore, you do not need to use serialization with MPI.","category":"page"},{"location":"shist/#Construction-and-conversion","page":"Static Histograms","title":"Construction and conversion","text":"","category":"section"},{"location":"shist/","page":"Static Histograms","title":"Static Histograms","text":"You can create an SHist from a Hist with the constructor.","category":"page"},{"location":"shist/","page":"Static Histograms","title":"Static Histograms","text":"using IRMA\nusing OnlineStats\nh = fit!(Hist(-5:0.2:5), randn(1_000))\nsh = SHist(h)","category":"page"},{"location":"shist/","page":"Static Histograms","title":"Static Histograms","text":"Note that an SHist is immutable. If you want to do anything real with it, you need to change it back into a Hist.","category":"page"},{"location":"shist/","page":"Static Histograms","title":"Static Histograms","text":"hh = Hist(sh)","category":"page"},{"location":"shist/","page":"Static Histograms","title":"Static Histograms","text":"The conversions are very fast (~300 ns).","category":"page"},{"location":"shist/","page":"Static Histograms","title":"Static Histograms","text":"If you have a Series of histograms you can also go back and forth with the following...","category":"page"},{"location":"shist/","page":"Static Histograms","title":"Static Histograms","text":"s1 = Series(Hist(-5:0.2:5), Hist(-10:0.1:10)) ; fit!(s1, randn(1000))\nsh1 = Series(SHist.(s1.stats)...)\nss1 = Series(Hist.(sh1.stats)...)","category":"page"},{"location":"shist/","page":"Static Histograms","title":"Static Histograms","text":"Named groups are also possible.","category":"page"},{"location":"shist/","page":"Static Histograms","title":"Static Histograms","text":"s2 = Series(h1=Hist(-5:0.2:5), h2=Hist(-10:0.1:10)) ; fit!(s2, randn(1000))\nsh2 = Series((; zip(keys(s2.stats), SHist.(values(s2.stats)))...))","category":"page"},{"location":"shist/","page":"Static Histograms","title":"Static Histograms","text":"Series is the only collection type that is implemented. Note that there is no way to make a FTSeries isbits (due to the function objects), so you'll have to construct a different object from its parts.","category":"page"},{"location":"shist/#Merging","page":"Static Histograms","title":"Merging","text":"","category":"section"},{"location":"shist/","page":"Static Histograms","title":"Static Histograms","text":"Functions are provided to handle merging Static Histograms and their collections. Note that since they are immutable, there is no merge! method. The merge occurs by converting to a Hist, doing the merge, and then converting back to a SHist.","category":"page"},{"location":"shist/","page":"Static Histograms","title":"Static Histograms","text":"s1 = fit!(Hist(-5:0.2:5), randn(1000)) ; sh1 = SHist(s1)\ns2 = fit!(Hist(-5:0.2:5), randn(1000)) ; sh2 = SHist(s2)\n\nshm = merge(sh1, sh2)","category":"page"},{"location":"shist/","page":"Static Histograms","title":"Static Histograms","text":"For Series, we have to use a special function, mergeStatsCollectionWithSHist.","category":"page"},{"location":"shist/","page":"Static Histograms","title":"Static Histograms","text":"ser1   = Series(h1=Hist(-5:0.2:5), h2=Hist(-10:0.2:10)) ; fit!(ser1,  randn(1_000));\nsher1  = Series((; zip(keys(ser1.stats), SHist.(values(ser1.stats)))... ))\n\nser2 = Series(h1=Hist(-5:0.2:5), h2=Hist(-10:0.2:10)) ; fit!(ser2, randn(1_000));\nsher2 = Series((; zip(keys(ser2.stats), SHist.(values(ser2.stats)))... ))\n\nsherm = mergeStatsCollectionWithSHist(sher1, sher2)","category":"page"},{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"","category":"page"},{"location":"api/","page":"API","title":"API","text":"Modules = [IRMA]","category":"page"},{"location":"api/#IRMA.DataSetEntry","page":"API","title":"IRMA.DataSetEntry","text":"DataSetEntry is an object that represents an HDF5 dataset that can be in many files\n\n\n\n\n\n","category":"type"},{"location":"api/#IRMA.SHist-Tuple{Hist}","page":"API","title":"IRMA.SHist","text":"SHist(h::Hist)\n\nCreate a SHist (Static Histogram) from an already filled Hist. \n\nNote that the SHist is immutable.\n\n\n\n\n\n","category":"method"},{"location":"api/#IRMA.Stopwatch","page":"API","title":"IRMA.Stopwatch","text":"Stopwatch\n\nStopwatch is an object that keeps track of MPI.Wtime when asked.\n\nAt construction time, the \"start\" time is recorded.\nCall `stamp(sw, stamp)` to record the current MPI.Wtime and label\n                        it with \"stamp\"\n\nCall `asNamedTuple(sw)` for transferring to other MPI ranks. The\nresulting NamedTuple with be `isbits` type.\n\n\n\n\n\n","category":"type"},{"location":"api/#IRMA.Stopwatch-Tuple{NamedTuple}","page":"API","title":"IRMA.Stopwatch","text":"Stopwatch(nt::NamedTuple)\n\nCreate a Stopwatch from a previously filled named tuple\n\n\n\n\n\n","category":"method"},{"location":"api/#IRMA.Stopwatch-Tuple{}","page":"API","title":"IRMA.Stopwatch","text":"Stopwatch()\n\nCreate a Stopwatch. The \"start\" entry will automatically be made\nand the MPI.Wtime will be filled in.\n\n\n\n\n\n","category":"method"},{"location":"api/#OnlineStats.Hist-Tuple{SHist}","page":"API","title":"OnlineStats.Hist","text":"Hist(sh::SHist)\n\nCreate an OnlineStats.Hist from a SHist\n\n\n\n\n\n","category":"method"},{"location":"api/#IRMA.addFileToDataSetEntry-Tuple{DataSetEntry,String,Int64}","page":"API","title":"IRMA.addFileToDataSetEntry","text":"Add a file to the DataSetEntry - This will also record what row numbers should come from this file\n\n\n\n\n\n","category":"method"},{"location":"api/#IRMA.analyzeInputFiles","page":"API","title":"IRMA.analyzeInputFiles","text":"analyzeInputFiles(path, outFileName=\"out.jld2\")\n\nAnalyze input files and write dataset data to a jld2 file.\nUse this one for a \"CLI like\" experience. For example\n\nanalyzeInputFiles( joinpath(ENV[\"CSCRATCH\"], \"irmaData2\", \"2C\"), \"2C_analyze.jld2\")\n\n\n\n\n\n","category":"function"},{"location":"api/#IRMA.analyzeInputFiles-Tuple{Array{String,1},Array{String,1},Dict{String,DataSetEntry}}","page":"API","title":"IRMA.analyzeInputFiles","text":"analyzeInputFiles(inFiles::Vector{String}, groups, inDataSets)\n\nFill groups and inFiles from a vector of file names to be read and analyzed.\n\nA good way to get a list of file names is to use Glob.glob(path).\n\n\n\n\n\n","category":"method"},{"location":"api/#IRMA.analyzeInputFiles-Tuple{String,Array{String,1},Dict{String,DataSetEntry}}","page":"API","title":"IRMA.analyzeInputFiles","text":"analyzeInputFiles(path, groups, inDataSets)\n\nFill groups and inFiles from a vector of file names to be read and analyzed.\n\n\n\n\n\n","category":"method"},{"location":"api/#IRMA.asNamedTuple-Tuple{Stopwatch}","page":"API","title":"IRMA.asNamedTuple","text":"asNamedTuple(sw::Stopwatch)\n\nConvert `sw` into a `NamedTuple` for MPI transport.\n\n\n\n\n\n","category":"method"},{"location":"api/#IRMA.chooseDataSets","page":"API","title":"IRMA.chooseDataSets","text":"chooseDataSets(inDataSets, selectThese=[], group=\"\")\n\nChoose the datasets to use from the file. You need the DataSetEntry dictionary (`inDataSets`), a\nstring vector (`selectThese`) of the dataset names you want. If many come from the same group, you can\nset `group` to that group name and relative names in `selectThese` (if there is an absolute path in `selectThese`,\nthen the group name won't be applied).\n\nA vector of the matching DataSetEntry elements will be returned.\n\n\n\n\n\n","category":"function"},{"location":"api/#IRMA.deserializeArray-Tuple{Any,Any}","page":"API","title":"IRMA.deserializeArray","text":"deserializeArray(a, s)     When you use MPI.Gather, you get one long array with all of the contents from the ranks mushed together.     They need to be separated and deserialized.\n\nReturns an array of deserialized objects\n\na is the array of data all mushed together\ns is an array of the data size for each rank\n\n\n\n\n\n","category":"method"},{"location":"api/#IRMA.displayDataSetEntries-Tuple{Dict}","page":"API","title":"IRMA.displayDataSetEntries","text":"displayDataSetEntries(inDataSets::Dict)\nPrint info about DataSetEntry objects in dictionary.\n\n\n\n\n\n","category":"method"},{"location":"api/#IRMA.makeGetStructureVisitor-Tuple{Any,Any}","page":"API","title":"IRMA.makeGetStructureVisitor","text":"makeGetStructureVisitor(groups, datasets)     Populate groups and datasets structures with this object\n\nIf this object is a group, add the name to the groups list if it is not there\nIf this object is a dataset, and if it is the first time we've seen it, then add this dataset to the DataSetEntry structure.\n then, everytime we see this dataset, we'll add the size to the structure and a mapping to the input file\n\n\n\n\n\n","category":"method"},{"location":"api/#IRMA.mergeStatsCollectionWithSHist-Tuple{OnlineStatsBase.Series,OnlineStatsBase.Series}","page":"API","title":"IRMA.mergeStatsCollectionWithSHist","text":"mergeStatsCollectionWithSHist(s1::Series, s2::Series)\n\nBecause Static Histograms are immutable, we cannot use the standard `OnlineStats.merge` \n    function (actually, it is `OnlineStatsBase.merge`) because the underlying function \n    is `merge!`.\n\n\n\n\n\n","category":"method"},{"location":"api/#IRMA.mpiAllgatherSerialized-Tuple{Any,Any}","page":"API","title":"IRMA.mpiAllgatherSerialized","text":"mpiAllgatherSerialized(obj, comm)\n\nSerializes the object, determines the size, calls MPI.Allgather on the sizes,\ncalls MPI.Gather on the serialized data, deserializes the data.\n\nReturns an array of deserialized data from all of the ranks.\nAll of the ranks get the full data in an array.\n\nobj is the object to serialize and send\ncomm is the MPI communicator\n\n\n\n\n\n","category":"method"},{"location":"api/#IRMA.mpiGatherSerialized-NTuple{4,Any}","page":"API","title":"IRMA.mpiGatherSerialized","text":"mpiGatherSerialized(obj, isroot, root, comm)\n\nSerializes the object, determines the size, calls MPI.Gather on the sizes,\ncalls MPI.Gather on the serialized data, deserializes the data.\n\nReturns an array of deserialized data from all of the ranks. Only the root rank\ngets the full gathered array\n\nobj is the object to serialize and send\nisroot is a boolean which is true if this rank is the root rank\nroot is the root rank id\ncomm is the MPI communicator\n\n\n\n\n\n","category":"method"},{"location":"api/#IRMA.mpi_shared_array-Union{Tuple{T}, Tuple{MPI.Comm,Type{T},Tuple{Vararg{Int64,N} where N}}} where T","page":"API","title":"IRMA.mpi_shared_array","text":"mpisharedarray(nodecomm, Type, size; ownerrank)     From https://github.com/JuliaParallel/MPI.jl/blob/master/test/testsharedwin.jl     Create a shared array, allocated by process with rank owner_rank on the     nodecomm provided (i.e. when `MPI.Commrank(nodecomm) == ownerrank`). Assumes all     processes on the nodecomm are on the same node, or, more precisely that they     can create/access a shared mem block between them.     usage:     nrows, ncols = 100, 11     const arr = mpisharedarray(MPI.COMMWORLD, Int, (nrows, nworkersnode), ownerrank=0)\n\n\n\n\n\n","category":"method"},{"location":"api/#IRMA.partitionDS-Tuple{Int64,Int64}","page":"API","title":"IRMA.partitionDS","text":"partitionDS(dsLength, nRanks)\n\nGiven the length of a dataset (or anything, really), determine and return partitions over \nnRanks MPI ranks that are as close to the same size as possible. This is really just a wrapper \naround Distributed.splitrange with some added error checking to produce nice messages.\n\n\n\n\n\n","category":"method"},{"location":"api/#IRMA.rankConfig","page":"API","title":"IRMA.rankConfig","text":"rankConfig(comm)     Determines the MPI configuration of this rank, in three spaces\n\n- Global space - space of all ranks\n- Node space - The space of ranks on a particular node\n- Among Node Roots space - The space of node-root ranks\n\nThis function determines,\n* The global rank number (myRank)\n* The number of global ranks (nprocs)\n* The # of the root rank in global space (rootRank)\n* True if this rank is global root (isRoot)\n\n* The number of ranks on this node (nprocsOnNode)\n* The node-space rank number (myRankOnNode)\n* The # of the root rank in node-space (rootRankOnNode)\n* True if this rank is a root rank in node-space (isRootOnNode)\n\n* The number of nodes in use (nNodes)\n* The # of the node this rank is on (myNode)\n* If this rank is a node root rank, # of rank within that space (myRankAmongNodeRoots)\n* If this rank is a node root rank, the # of ranks in that space (nprocsAmongNodeRoots)\n\nFor the last two, disregard if this rank is not a node root rank (they are the values\n   in the Among Node non-root ranks, which isn't all that useful)\n\nReturns a Named Tuple of information above along with the commOnNode communicator\n\n\n\n\n\n","category":"function"},{"location":"api/#IRMA.rankTimings-Tuple{Any}","page":"API","title":"IRMA.rankTimings","text":"rankTimings(arrayOfNamedTuples)\n\nProcess an array of named tuples (e.g. from MPI ranks from `asNamedTuple`\nthat was gathered and saved) turning them into an array of NamedTuples\nof timing differences for each step.\n\n\n\n\n\n","category":"method"},{"location":"api/#IRMA.rankTotalTime-Tuple{Any}","page":"API","title":"IRMA.rankTotalTime","text":"rankTotalTime(arrayOfNamedTuples)\n\nReturn an array for the total time of each ranks\n\n\n\n\n\n","category":"method"},{"location":"api/#IRMA.stamp-Tuple{Stopwatch,String}","page":"API","title":"IRMA.stamp","text":"stamp(sw::Stopwatch, stamp::String)\n\nFor a `Stopwatch` `sw`, record the MPI time and the stamp.\n\nIt returns the elapsed time from the previous stamp.\n\n\n\n\n\n","category":"method"},{"location":"api/#IRMA.visitH5Contents-Tuple{String,Union{HDF5.File, HDF5.Group},Any}","page":"API","title":"IRMA.visitH5Contents","text":"visitH5Contents(inH5, isMine, visitor)\n\nWalk the contents of an H5 file, visiting each group and\ndataset in the hierarchy.\n\ninH5 is the opened HDF5 file object or group object to walk\n\nThis functions will walk within HDF5 file and group objects and will\nrecursively dive into a hierarchy of groups. The visted object is passed\nto the visitor function (it must handle whatever object is passed in)\n\n\n\n\n\n","category":"method"},{"location":"stopwatch/#Stopwatch-for-MPI","page":"Stopwatch for MPI","title":"Stopwatch for MPI","text":"","category":"section"},{"location":"stopwatch/","page":"Stopwatch for MPI","title":"Stopwatch for MPI","text":"It is often important to time operations in MPI. The Stopwatch object will do that for you by recording the current MPI time (with MPI.Wtime) when you ask for a \"stamp\" given a label. The \"start\" stamp is recorded automatically when the Stopwatch is created. You add more stamps with the stamp function. If you want to transport the Stopwatch over MPI, then you can turn it into a NamedTuple with asNamedTuple (the NamedTuple will be isbits compatible).","category":"page"},{"location":"stopwatch/","page":"Stopwatch for MPI","title":"Stopwatch for MPI","text":"# Note that this block is not run because it crashes the GitHub Action\n# that generates the documentation. I think this happens because\n# MPI.Wtime is called.  So this sketch of what to do will have\n# to suffice\n\nusing IRMA\n\nsw = Stopwatch()  # The start stamp is automatically recorded\n\n# Do stuff\nsleep(0.2)\nstamp(sw, \"A\")\n\n# Do more stuff\nsleep(0.2)\nstamp(sw, \"B\")\n\n# Now we want to do MPI.Gather or something similar\nnt = asNamedTuple(sw)\n# allTimes = MPI.Gather(nt, root, comm)","category":"page"},{"location":"#IRMA.jl-Documentation","page":"IRMA.jl Documentation","title":"IRMA.jl Documentation","text":"","category":"section"},{"location":"","page":"IRMA.jl Documentation","title":"IRMA.jl Documentation","text":"IRMA supports the Muon g-2 IRMA analysis with Julia code.","category":"page"},{"location":"partitionDS/#Partitioning-a-DataSet","page":"Partitioning a DataSet","title":"Partitioning a DataSet","text":"","category":"section"},{"location":"partitionDS/","page":"Partitioning a DataSet","title":"Partitioning a DataSet","text":"When reading a dataset with multiple MPI ranks, the dataset must be partitioned amongst the ranks. Given the length of the dataset and the number of MPI ranks, partitionDS will determine start and end indices for each MPI rank such that the number of elements per rank are as equal as possible.","category":"page"},{"location":"partitionDS/","page":"Partitioning a DataSet","title":"Partitioning a DataSet","text":"Note that partitionDS is really a wrapper around Distributed.splitrange.","category":"page"},{"location":"partitionDS/","page":"Partitioning a DataSet","title":"Partitioning a DataSet","text":"using IRMA\npartitionDS(1_000_000, 64)","category":"page"},{"location":"partitionDS/","page":"Partitioning a DataSet","title":"Partitioning a DataSet","text":"See an example Pluto Notebook and a static version.","category":"page"},{"location":"tips/#Tips-for-doing-stuff","page":"Tips for doing stuff","title":"Tips for doing stuff","text":"","category":"section"},{"location":"tips/","page":"Tips for doing stuff","title":"Tips for doing stuff","text":"This page includes tips that I want to remember.","category":"page"},{"location":"tips/#Running-with-MPI-and-HDF5","page":"Tips for doing stuff","title":"Running with MPI and HDF5","text":"","category":"section"},{"location":"tips/","page":"Tips for doing stuff","title":"Tips for doing stuff","text":"As of October 14, 2020, you must use the master branch of HDF5.jl. So,","category":"page"},{"location":"tips/","page":"Tips for doing stuff","title":"Tips for doing stuff","text":"] add HDF5#master","category":"page"},{"location":"tips/","page":"Tips for doing stuff","title":"Tips for doing stuff","text":"Remember to build and test accordingly.","category":"page"},{"location":"tips/","page":"Tips for doing stuff","title":"Tips for doing stuff","text":"Before running a job, everything should be instantiated and pre-compiled by Julia. You can do this easily from the command line with,","category":"page"},{"location":"tips/","page":"Tips for doing stuff","title":"Tips for doing stuff","text":"julia --project -e 'using Pkg; pkg\"instantiate\"'\njulia --project -e 'using Pkg; pkg\"precompile\"'","category":"page"},{"location":"tips/","page":"Tips for doing stuff","title":"Tips for doing stuff","text":"Note that --project activates the environment for the current directory.","category":"page"},{"location":"tips/#Saving-information-from-ranks","page":"Tips for doing stuff","title":"Saving information from ranks","text":"","category":"section"},{"location":"tips/","page":"Tips for doing stuff","title":"Tips for doing stuff","text":"You may want to collect information from MPI ranks and write that out at the end of the job. The best way to do that is through a NamedTuple, since MPI.Gather can deal with that type directly (so long as the contents are isbitstype). The problem with NamedTuple is that it is immutable, so you can't grow it as the code executes.","category":"page"},{"location":"tips/","page":"Tips for doing stuff","title":"Tips for doing stuff","text":"You can use a dictionary as a convenient way to collect information and then convert that to a NamedTuple before gathering and writing. The keys must be symbols. For example,","category":"page"},{"location":"tips/","page":"Tips for doing stuff","title":"Tips for doing stuff","text":"rankLog = Dict()\n# ...do stuff...\nrankLog[:startIndex] = 4\nrankLog[:endIndex]  = 100\n# ...\nrankLog[:nPassed] = 289\nrankLog[:meanWeight] = 5.667\n# ...\nnt = (; rankLog...)    # Convert to Named tuple","category":"page"},{"location":"tips/","page":"Tips for doing stuff","title":"Tips for doing stuff","text":"Note that for a dictionary, the order of input is not maintained.","category":"page"},{"location":"tips/","page":"Tips for doing stuff","title":"Tips for doing stuff","text":"Of course, you can also just make the NamedTuple directly (and then the order is set by the construction).","category":"page"},{"location":"tips/","page":"Tips for doing stuff","title":"Tips for doing stuff","text":"nt = (startIndex=4, endIndex=100, nPassed=289, meanWeight=5.667)","category":"page"}]
}
